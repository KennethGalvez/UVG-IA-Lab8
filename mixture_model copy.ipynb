{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gráfica es para saber los clusters óptimos con el algoritmo de cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def gaussian(X, mean, covariance):\n",
    "    d = X.shape[1]\n",
    "    # Add a small positive constant to the diagonal of covariance matrix\n",
    "    covariance += np.eye(d) * 1e-8\n",
    "    coef = 1 / ((2 * np.pi) ** (d / 2) * np.linalg.det(covariance) ** 0.5)\n",
    "    diff = X - mean\n",
    "    exponent = -0.5 * np.sum(np.dot(diff, np.linalg.inv(covariance)) * diff, axis=1)\n",
    "    return coef * np.exp(exponent)\n",
    "\n",
    "\n",
    "def initialize_parameters(X, n_components):\n",
    "    n, d = X.shape\n",
    "    idx = np.random.choice(n, n_components, replace=False)\n",
    "    means = X[idx]\n",
    "    covariances = [\n",
    "        np.diag(np.ones(d)) for _ in range(n_components)\n",
    "    ]  # create diagonal matrices\n",
    "    weights = np.full(n_components, 1 / n_components)\n",
    "    return means, covariances, weights\n",
    "\n",
    "\n",
    "def expectation(X, means, covariances, weights):\n",
    "    n, d = X.shape\n",
    "    n_components = len(means)\n",
    "    resp = np.zeros((n, n_components))\n",
    "\n",
    "    for i in range(n_components):\n",
    "        resp[:, i] = weights[i] * gaussian(X, means[i], covariances[i])\n",
    "    epsilon = 1e-8\n",
    "    resp /= resp.sum(axis=1, keepdims=True) + epsilon\n",
    "\n",
    "    return resp\n",
    "\n",
    "\n",
    "def maximization(X, resp, reg=1e-6):\n",
    "    n, d = X.shape\n",
    "    n_components = resp.shape[1]\n",
    "\n",
    "    nk = resp.sum(axis=0)\n",
    "    weights = nk / n\n",
    "    means = np.dot(resp.T, X) / nk[:, np.newaxis]\n",
    "\n",
    "    covariances = []\n",
    "    for i in range(n_components):\n",
    "        diff = X - means[i]\n",
    "        cov = np.dot(resp[:, i] * diff.T, diff) / nk[i]\n",
    "        cov += np.eye(d) * reg  # add regularization to covariance matrix\n",
    "        covariances.append(cov)\n",
    "\n",
    "    return means, covariances, weights\n",
    "\n",
    "\n",
    "def em_algorithm(X, n_components, max_iter=100, tol=1e-4, reg=1e-6):\n",
    "    means, covariances, weights = initialize_parameters(X, n_components)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        old_means = means.copy()\n",
    "        resp = expectation(X, means, covariances, weights)\n",
    "        means, covariances, weights = maximization(X, resp, reg=reg)\n",
    "\n",
    "        if np.linalg.norm(old_means - means) < tol:\n",
    "            break\n",
    "\n",
    "    return means, covariances, weights, resp\n",
    "\n",
    "\n",
    "def cross_validation(X, n_components_range, n_folds=5):\n",
    "    n = X.shape[0]\n",
    "    fold_size = n // n_folds\n",
    "    log_likelihoods = np.zeros((n_folds, len(n_components_range)))\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "        validation_indices = np.arange(fold * fold_size, (fold + 1) * fold_size)\n",
    "        train_indices = np.concatenate(\n",
    "            (np.arange(0, fold * fold_size), np.arange((fold + 1) * fold_size, n))\n",
    "        )\n",
    "        X_train = X[train_indices]\n",
    "        X_validation = X[validation_indices]\n",
    "\n",
    "        for i, n_components in enumerate(n_components_range):\n",
    "            means, covariances, weights, resp_train = em_algorithm(\n",
    "                X_train, n_components\n",
    "            )\n",
    "            resp_validation = expectation(X_validation, means, covariances, weights)\n",
    "            log_likelihoods[fold, i] = np.sum(\n",
    "                np.log(np.sum(resp_validation, axis=1) + 1e-8)\n",
    "            )\n",
    "\n",
    "    return log_likelihoods.mean(axis=0)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"cleaned_bank_transactions.csv\")\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X = pca.fit_transform(df)\n",
    "\n",
    "# Standardize the data\n",
    "#X = X.to_numpy()\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "# Check for NaN or infinite values\n",
    "if np.isnan(X).any() or np.isinf(X).any():\n",
    "    # Replace NaN or infinite values with 0\n",
    "    X = np.nan_to_num(X, nan=0, posinf=0, neginf=0)\n",
    "\n",
    "# Find the ideal number of clusters using cross-validation\n",
    "n_components_range = range(1, 11)\n",
    "average_log_likelihoods = cross_validation(X, n_components_range=n_components_range)\n",
    "\n",
    "plt.plot(n_components_range, average_log_likelihoods, marker=\"o\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Average Log-Likelihood\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafico del \"Gaussian Mixture Model\" con los clusters agrupados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "def gaussian(X, mean, covariance):\n",
    "    d = X.shape[1]\n",
    "    # Add a small positive constant to the diagonal of covariance matrix\n",
    "    covariance += np.eye(d) * 1e-8\n",
    "    coef = 1 / ((2 * np.pi) ** (d / 2) * np.linalg.det(covariance) ** 0.5)\n",
    "    diff = X - mean\n",
    "    exponent = -0.5 * np.sum(np.dot(diff, np.linalg.inv(covariance)) * diff, axis=1)\n",
    "    return coef * np.exp(exponent)\n",
    "\n",
    "\n",
    "def initialize_parameters(X, n_components):\n",
    "    n, d = X.shape\n",
    "    idx = np.random.choice(n, n_components, replace=False)\n",
    "    means = X[idx]\n",
    "    covariances = [\n",
    "        np.diag(np.ones(d)) for _ in range(n_components)\n",
    "    ]  # create diagonal matrices\n",
    "    weights = np.full(n_components, 1 / n_components)\n",
    "    return means, covariances, weights\n",
    "\n",
    "\n",
    "def expectation(X, means, covariances, weights):\n",
    "    n, d = X.shape\n",
    "    n_components = len(means)\n",
    "    resp = np.zeros((n, n_components))\n",
    "\n",
    "    for i in range(n_components):\n",
    "        resp[:, i] = weights[i] * gaussian(X, means[i], covariances[i])\n",
    "    epsilon = 1e-8\n",
    "    resp /= resp.sum(axis=1, keepdims=True) + epsilon\n",
    "\n",
    "    return resp\n",
    "\n",
    "\n",
    "def maximization(X, resp, reg=1e-6):\n",
    "    n, d = X.shape\n",
    "    n_components = resp.shape[1]\n",
    "\n",
    "    nk = resp.sum(axis=0)\n",
    "    weights = nk / n\n",
    "    means = np.dot(resp.T, X) / nk[:, np.newaxis]\n",
    "\n",
    "    covariances = []\n",
    "    for i in range(n_components):\n",
    "        diff = X - means[i]\n",
    "        cov = np.dot(resp[:, i] * diff.T, diff) / nk[i]\n",
    "        cov += np.eye(d) * reg  # add regularization to covariance matrix\n",
    "        covariances.append(cov)\n",
    "\n",
    "    return means, covariances, weights\n",
    "\n",
    "\n",
    "def em_algorithm(X, n_components, max_iter=100, tol=1e-4, reg=1e-6):\n",
    "    means, covariances, weights = initialize_parameters(X, n_components)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        old_means = means.copy()\n",
    "        resp = expectation(X, means, covariances, weights)\n",
    "        means, covariances, weights = maximization(X, resp, reg=reg)\n",
    "\n",
    "        if np.linalg.norm(old_means - means) < tol:\n",
    "            break\n",
    "\n",
    "    return means, covariances, weights, resp\n",
    "\n",
    "\n",
    "def cross_validation(X, n_components_range, n_folds=5):\n",
    "    n = X.shape[0]\n",
    "    fold_size = n // n_folds\n",
    "    log_likelihoods = np.zeros((n_folds, len(n_components_range)))\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "        validation_indices = np.arange(fold * fold_size, (fold + 1) * fold_size)\n",
    "        train_indices = np.concatenate(\n",
    "            (np.arange(0, fold * fold_size), np.arange((fold + 1) * fold_size, n))\n",
    "        )\n",
    "        X_train = X[train_indices]\n",
    "        X_validation = X[validation_indices]\n",
    "\n",
    "        for i, n_components in enumerate(n_components_range):\n",
    "            means, covariances, weights, resp_train = em_algorithm(\n",
    "                X_train, n_components\n",
    "            )\n",
    "            resp_validation = expectation(X_validation, means, covariances, weights)\n",
    "            log_likelihoods[fold, i] = np.sum(\n",
    "                np.log(np.sum(resp_validation, axis=1) + 1e-8)\n",
    "            )\n",
    "\n",
    "    return log_likelihoods.mean(axis=0)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"cleaned_bank_transactions.csv\")\n",
    "\n",
    "# Standardize the data\n",
    "X = df.to_numpy()\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "# Check for NaN or infinite values\n",
    "if np.isnan(X).any() or np.isinf(X).any():\n",
    "    # Replace NaN or infinite values with 0\n",
    "    X = np.nan_to_num(X, nan=0, posinf=0, neginf=0)\n",
    "\n",
    "# Find the ideal number of clusters using cross-validation\n",
    "n_components_range = range(1, 11)\n",
    "average_log_likelihoods = cross_validation(X, n_components_range=n_components_range)\n",
    "\n",
    "# Fit the Gaussian Mixture Model with the selected number of clusters\n",
    "n_components = np.argmax(average_log_likelihoods) + 1\n",
    "means, covariances, weights, resp = em_algorithm(X, n_components)\n",
    "\n",
    "# Assign each data point to a cluster\n",
    "cluster_assignments = np.argmax(resp, axis=1)\n",
    "\n",
    "# Plot the clusters\n",
    "fig, ax = plt.subplots()\n",
    "colors = [\"r\", \"g\", \"b\", \"y\", \"c\", \"m\", \"k\", \"orange\", \"purple\", \"lime\"]\n",
    "for i in range(n_components):\n",
    "    cluster_data = X[cluster_assignments == i]\n",
    "    ax.scatter(\n",
    "        cluster_data[:, 0], cluster_data[:, 1], c=colors[i], label=f\"Cluster {i + 1}\"\n",
    "    )\n",
    "\n",
    "# Plot the cluster means\n",
    "for i in range(n_components):\n",
    "    plt.scatter(\n",
    "        means[i, 0],\n",
    "        means[i, 1],\n",
    "        marker=\"*\",\n",
    "        s=200,\n",
    "        c=colors[i],\n",
    "        edgecolor=\"k\",\n",
    "        label=f\"Mean {i + 1}\",\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.legend()\n",
    "plt.title(f\"Gaussian Mixture Model with {n_components} Clusters\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
